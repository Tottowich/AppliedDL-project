{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 17:08:11.225253: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 17:08:11.812874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/theodor/anaconda3/envs/tf/lib/\n",
      "2023-02-18 17:08:11.812925: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/theodor/anaconda3/envs/tf/lib/\n",
      "2023-02-18 17:08:11.812931: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Plot model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from segmentation.unet import build_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 17:08:13.400438: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 17:08:13.404138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 17:08:13.404546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 17:08:13.405099: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 17:08:13.405487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 17:08:13.405774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 17:08:13.406011: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 17:08:13.841944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 17:08:13.842226: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 17:08:13.842450: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 17:08:13.842662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5398 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'residual_conv_block' (type ResidualConvBlock).\n\nin user code:\n\n    File \"/home/theodor/Code/Medical-Imageing/archs/segmentation/model_utils.py\", line 128, in call  *\n        return self.activation(self.seq(x)+self.skip(residual))\n    File \"/home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/keras_tensor.py\", line 268, in __hash__\n        raise TypeError(\n\n    TypeError: Exception encountered when calling layer 'batch_normalization' (type BatchNormalization).\n    \n    Tensors are unhashable (this tensor: KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 1), dtype=tf.float32, name=None), name='Encoder/residual_encoder_block_3/max_pooling2d_3/MaxPool:0', description=\"created by layer 'Encoder'\")). Instead, use tensor.ref() as the key.\n    \n    Call arguments received by layer 'batch_normalization' (type BatchNormalization):\n      • inputs=tf.Tensor(shape=(None, 8, 8, 1), dtype=float32)\n      • training=<KerasTensor: shape=(None, 16, 16, 1) dtype=float32 (created by layer 'Encoder')>\n\n\nCall arguments received by layer 'residual_conv_block' (type ResidualConvBlock):\n  • x=tf.Tensor(shape=(None, 8, 8, 257), dtype=float32)\n  • kwargs={'training': \"<KerasTensor: shape=(None, 16, 16, 1) dtype=float32 (created by layer 'Encoder')>\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m output_depth \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m output_activation \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m unet \u001b[39m=\u001b[39m build_unet(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     input_shape\u001b[39m=\u001b[39;49minput_shape,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     num_classes\u001b[39m=\u001b[39;49mnum_classes,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     filters\u001b[39m=\u001b[39;49mfilters,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     kernel_size\u001b[39m=\u001b[39;49mkernel_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     activation\u001b[39m=\u001b[39;49mactivation,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     depth_encoder\u001b[39m=\u001b[39;49mdepth_encoder,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     depth_decoder\u001b[39m=\u001b[39;49mdepth_decoder,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     drop_rate_encoder\u001b[39m=\u001b[39;49mdrop_rate_encoder,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     drop_rate_decoder\u001b[39m=\u001b[39;49mdrop_rate_decoder,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     output_depth\u001b[39m=\u001b[39;49moutput_depth,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     output_activation\u001b[39m=\u001b[39;49moutput_activation,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(unet\u001b[39m.\u001b[39msummary(expand_nested\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/Code/Medical-Imageing/archs/segmentation/unet.py:37\u001b[0m, in \u001b[0;36mbuild_unet\u001b[0;34m(input_shape, num_classes, filters, kernel_size, strides, padding, activation, depth_encoder, depth_decoder, drop_rate_encoder, drop_rate_decoder, output_depth, output_activation)\u001b[0m\n\u001b[1;32m     35\u001b[0m x \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39minput_shape)\n\u001b[1;32m     36\u001b[0m encoder_outputs \u001b[39m=\u001b[39m encoder(x)\n\u001b[0;32m---> 37\u001b[0m decoder \u001b[39m=\u001b[39m build_decoder(\n\u001b[1;32m     38\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m     39\u001b[0m     num_classes\u001b[39m=\u001b[39;49mnum_classes,\n\u001b[1;32m     40\u001b[0m     filters\u001b[39m=\u001b[39;49mfilters[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m:],\n\u001b[1;32m     41\u001b[0m     kernel_size\u001b[39m=\u001b[39;49mkernel_size,\n\u001b[1;32m     42\u001b[0m     strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[1;32m     43\u001b[0m     padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m     44\u001b[0m     activation\u001b[39m=\u001b[39;49mactivation,\n\u001b[1;32m     45\u001b[0m     depth\u001b[39m=\u001b[39;49mdepth_decoder,\n\u001b[1;32m     46\u001b[0m     output_depth\u001b[39m=\u001b[39;49moutput_depth,\n\u001b[1;32m     47\u001b[0m     output_activation\u001b[39m=\u001b[39;49moutput_activation,\n\u001b[1;32m     48\u001b[0m     drop_rate\u001b[39m=\u001b[39;49mdrop_rate_decoder,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     50\u001b[0m y \u001b[39m=\u001b[39m decoder(encoder_outputs[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m     51\u001b[0m unet \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39mx, outputs\u001b[39m=\u001b[39my)\n",
      "File \u001b[0;32m~/Code/Medical-Imageing/archs/segmentation/decoders.py:309\u001b[0m, in \u001b[0;36mbuild_decoder\u001b[0;34m(encoder_outputs, num_classes, filters, kernel_size, strides, padding, activation, depth, output_depth, output_activation, drop_rate, decoder_type)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_decoder\u001b[39m( \u001b[39m# Type of decoder to use (concat, add)\u001b[39;00m\n\u001b[1;32m    283\u001b[0m                 encoder_outputs:List[tf\u001b[39m.\u001b[39mTensor],\n\u001b[1;32m    284\u001b[0m                 num_classes:\u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 drop_rate:List[\u001b[39mfloat\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m,\n\u001b[1;32m    294\u001b[0m                 decoder_type:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconcat\u001b[39m\u001b[39m\"\u001b[39m,):\n\u001b[1;32m    296\u001b[0m     builder \u001b[39m=\u001b[39m DecoderBuilder(decoder_type\u001b[39m=\u001b[39mdecoder_type,\n\u001b[1;32m    297\u001b[0m                                 num_classes\u001b[39m=\u001b[39mnum_classes,\n\u001b[1;32m    298\u001b[0m                                 filters\u001b[39m=\u001b[39mfilters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m                                 encoder_outputs\u001b[39m=\u001b[39mencoder_outputs,\n\u001b[1;32m    308\u001b[0m                             )\n\u001b[0;32m--> 309\u001b[0m     model \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39;49mbuild()\n\u001b[1;32m    310\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Code/Medical-Imageing/archs/segmentation/decoders.py:266\u001b[0m, in \u001b[0;36mDecoderBuilder.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal \u001b[39m=\u001b[39m DecoderBlockNoSkip(filters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes,\n\u001b[1;32m    258\u001b[0m                                 kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, \n\u001b[1;32m    259\u001b[0m                                 strides\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m                                 drop_rate\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, \n\u001b[1;32m    264\u001b[0m                                 in_channels\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m layers\n\u001b[0;32m--> 266\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_call()\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n",
      "File \u001b[0;32m~/Code/Medical-Imageing/archs/segmentation/decoders.py:274\u001b[0m, in \u001b[0;36mDecoderBuilder._init_call\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m x \u001b[39m=\u001b[39m inp\n\u001b[1;32m    273\u001b[0m \u001b[39mfor\u001b[39;00m i,layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[0;32m--> 274\u001b[0m     x \u001b[39m=\u001b[39m layer(x, skips[i])\n\u001b[1;32m    275\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal(x)\n\u001b[1;32m    276\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39mencoder_outputs[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDecoder\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileexls54nn.py:13\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mactivation, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mseq, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mskip, (ag__\u001b[39m.\u001b[39mld(residual),), \u001b[39mNone\u001b[39;00m, fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'residual_conv_block' (type ResidualConvBlock).\n\nin user code:\n\n    File \"/home/theodor/Code/Medical-Imageing/archs/segmentation/model_utils.py\", line 128, in call  *\n        return self.activation(self.seq(x)+self.skip(residual))\n    File \"/home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages/keras/engine/keras_tensor.py\", line 268, in __hash__\n        raise TypeError(\n\n    TypeError: Exception encountered when calling layer 'batch_normalization' (type BatchNormalization).\n    \n    Tensors are unhashable (this tensor: KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 1), dtype=tf.float32, name=None), name='Encoder/residual_encoder_block_3/max_pooling2d_3/MaxPool:0', description=\"created by layer 'Encoder'\")). Instead, use tensor.ref() as the key.\n    \n    Call arguments received by layer 'batch_normalization' (type BatchNormalization):\n      • inputs=tf.Tensor(shape=(None, 8, 8, 1), dtype=float32)\n      • training=<KerasTensor: shape=(None, 16, 16, 1) dtype=float32 (created by layer 'Encoder')>\n\n\nCall arguments received by layer 'residual_conv_block' (type ResidualConvBlock):\n  • x=tf.Tensor(shape=(None, 8, 8, 257), dtype=float32)\n  • kwargs={'training': \"<KerasTensor: shape=(None, 16, 16, 1) dtype=float32 (created by layer 'Encoder')>\"}"
     ]
    }
   ],
   "source": [
    "H = 256\n",
    "W = 256\n",
    "C = 1\n",
    "input_shape = (H,W,C)\n",
    "num_classes = 1\n",
    "filters = [16,32,64,128,256,512]\n",
    "kernel_size = 3\n",
    "strides = 1\n",
    "padding = \"same\"\n",
    "activation = \"relu\"\n",
    "drop_rate_encoder = [0.0]\n",
    "drop_rate_decoder = [0.0]\n",
    "depth_encoder = [0]\n",
    "depth_decoder = [1]\n",
    "output_depth = 1\n",
    "output_activation = \"sigmoid\"\n",
    "\n",
    "unet = build_unet(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    filters=filters,\n",
    "    kernel_size=kernel_size,\n",
    "    strides=strides,\n",
    "    padding=padding,\n",
    "    activation=activation,\n",
    "    depth_encoder=depth_encoder,\n",
    "    depth_decoder=depth_decoder,\n",
    "    drop_rate_encoder=drop_rate_encoder,\n",
    "    drop_rate_decoder=drop_rate_decoder,\n",
    "    output_depth=output_depth,\n",
    "    output_activation=output_activation,\n",
    ")\n",
    "print(unet.summary(expand_nested=True))\n",
    "# plot_model(model=unet, to_file='unet.png', show_shapes=True, show_layer_names=True,expand_nested=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128, 64, 32, 16, 8, 4, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters[::-1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding layer 0 with input shape (None, 1, 1, 256) and skip shape (None, 2, 2, 128)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"decoder_block_concat_0\" (type DecoderBlockConcat).\n\nin user code:\n\n    File \"/home/theodor/Code/Medical-Imageing/archs/segmentation/decoders.py\", line 82, in call  *\n        x = self.concat([x, skip])\n    File \"/home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages/keras/layers/merging/concatenate.py\", line 131, in build\n        raise ValueError(err_msg)\n\n    ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 1, 1, 256), (None, 2, 2, 128)]\n\n\nCall arguments received by layer \"decoder_block_concat_0\" (type DecoderBlockConcat):\n  • x=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n  • skip=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n  • kwargs={'training': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/theodor/Code/Medical-Imageing/archs/testspace.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m decoder \u001b[39m=\u001b[39m build_decoder(ys, filters\u001b[39m=\u001b[39;49mfilters[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m1\u001b[39;49m:], kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, strides\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m\"\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m\"\u001b[39;49m, depth\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, drop_rate\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m)\n",
      "File \u001b[0;32m~/Code/Medical-Imageing/archs/segmentation/decoders.py:273\u001b[0m, in \u001b[0;36mbuild_decoder\u001b[0;34m(encoder_outputs, filters, kernel_size, strides, padding, activation, depth, drop_rate, decoder_type)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_decoder\u001b[39m( \u001b[39m# Type of decoder to use (concat, add)\u001b[39;00m\n\u001b[1;32m    254\u001b[0m                 encoder_outputs:List[tf\u001b[39m.\u001b[39mTensor],\n\u001b[1;32m    255\u001b[0m                 filters:List[\u001b[39mint\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 drop_rate:List[\u001b[39mfloat\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m,\n\u001b[1;32m    262\u001b[0m                 decoder_type:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconcat\u001b[39m\u001b[39m\"\u001b[39m,):\n\u001b[1;32m    264\u001b[0m     builder \u001b[39m=\u001b[39m DecoderBuilder(decoder_type\u001b[39m=\u001b[39mdecoder_type,\n\u001b[1;32m    265\u001b[0m                             filters\u001b[39m=\u001b[39mfilters,\n\u001b[1;32m    266\u001b[0m                             kernel_size\u001b[39m=\u001b[39mkernel_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m                             drop_rate\u001b[39m=\u001b[39mdrop_rate,\n\u001b[1;32m    272\u001b[0m                             encoder_outputs\u001b[39m=\u001b[39mencoder_outputs)\n\u001b[0;32m--> 273\u001b[0m     model \u001b[39m=\u001b[39m builder\u001b[39m.\u001b[39;49mbuild()\n\u001b[1;32m    274\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Code/Medical-Imageing/archs/segmentation/decoders.py:243\u001b[0m, in \u001b[0;36mDecoderBuilder.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDecoder type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder_type\u001b[39m}\u001b[39;00m\u001b[39m not supported\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    242\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m layers\n\u001b[0;32m--> 243\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_call()\n\u001b[1;32m    244\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n",
      "File \u001b[0;32m~/Code/Medical-Imageing/archs/segmentation/decoders.py:251\u001b[0m, in \u001b[0;36mDecoderBuilder._init_call\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mfor\u001b[39;00m i,layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[1;32m    250\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAdding layer \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m with input shape \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and skip shape \u001b[39m\u001b[39m{\u001b[39;00mskips[i]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 251\u001b[0m     x \u001b[39m=\u001b[39m layer(x, skips[i])\n\u001b[1;32m    252\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m], outputs\u001b[39m=\u001b[39mx)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filej9wrzju2.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x, skip, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mseq, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 11\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconcat, ([ag__\u001b[39m.\u001b[39mld(x), ag__\u001b[39m.\u001b[39mld(skip)],), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconvT, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"decoder_block_concat_0\" (type DecoderBlockConcat).\n\nin user code:\n\n    File \"/home/theodor/Code/Medical-Imageing/archs/segmentation/decoders.py\", line 82, in call  *\n        x = self.concat([x, skip])\n    File \"/home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages/keras/layers/merging/concatenate.py\", line 131, in build\n        raise ValueError(err_msg)\n\n    ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 1, 1, 256), (None, 2, 2, 128)]\n\n\nCall arguments received by layer \"decoder_block_concat_0\" (type DecoderBlockConcat):\n  • x=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n  • skip=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n  • kwargs={'training': 'None'}"
     ]
    }
   ],
   "source": [
    "decoder = build_decoder(ys, filters=filters[::-1][1:], kernel_size=3, strides=1, padding=\"same\", activation=\"relu\", depth=0, drop_rate=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b943d0b5534f5ef85c0420b5997dcb3cb706b77c7855306dea748f7a63e44caf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
